{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'cure/'\n",
    "\n",
    "output_directory = 'finalclean/'\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done :)\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        #Read each CSV file\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        #Sort data by 'smiles' and 'weight' in descending order (higher weight is better)\n",
    "        sorted_data = data.sort_values(by=['smiles', 'weight'], ascending=[True,False])\n",
    "\n",
    "        #Remove duplicates , keeping the first entry after sorting, which is the one with higher weight\n",
    "        best_values_data = sorted_data.drop_duplicates(subset='smiles', keep='first')\n",
    "\n",
    "        #Sort the cleaned data to the output directory with the same filename\n",
    "        output_file_path = os.path.join(output_directory, filename)\n",
    "        best_values_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print('All done :)')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cured data (before cleaning):\n",
      "Rows Counted 9061 in the csv aqsol_cure.csv:\n",
      "Rows Counted 1354 in the csv aqua_cure.csv:\n",
      "Rows Counted 28675 in the csv chembl_cure.csv:\n",
      "Rows Counted 1157 in the csv esol_cure.csv:\n",
      "Rows Counted 81935 in the csv kinect_cure.csv:\n",
      "Rows Counted 3766 in the csv ochem_cure.csv:\n",
      "Rows Counted 2001 in the csv phys_cure.csv:\n",
      "Cleaned data (after cleaning):\n",
      "Rows Counted 8701 in the csv aqsol_cure.csv:\n",
      "Rows Counted 1301 in the csv aqua_cure.csv:\n",
      "Rows Counted 26377 in the csv chembl_cure.csv:\n",
      "Rows Counted 1110 in the csv esol_cure.csv:\n",
      "Rows Counted 81891 in the csv kinect_cure.csv:\n",
      "Rows Counted 3665 in the csv ochem_cure.csv:\n",
      "Rows Counted 2001 in the csv phys_cure.csv:\n"
     ]
    }
   ],
   "source": [
    "print('Cured data (before cleaning):')\n",
    "path = 'C:\\\\Users\\\\sbnpa\\\\SolCuration\\\\cure'\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.csv'):\n",
    "        full_path = os.path.join(path, filename)  # Create the full path to the file\n",
    "        with open(full_path, 'r', encoding=\"latin-1\") as fileObj:\n",
    "            # -1 to exclude the header\n",
    "            print(\"Rows Counted {} in the csv {}:\".format(len(fileObj.readlines()) - 1, filename))\n",
    "\n",
    "print('Cleaned data (after cleaning):')\n",
    "path = 'C:\\\\Users\\\\sbnpa\\\\SolCuration\\\\finalclean'\n",
    "for filename in os.listdir(path):\n",
    "    full_path = os.path.join(path, filename)  # Create the full path to the file\n",
    "    with open(full_path, 'r', encoding=\"latin-1\") as fileObj:\n",
    "        # -1 to exclude the header\n",
    "        print(\"Rows Counted {} in the csv {}:\".format(len(fileObj.readlines()) - 1, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I combined all the \\cure data into one file :))\n"
     ]
    }
   ],
   "source": [
    "#join all csv files\n",
    "\n",
    "# List to hold dataframes\n",
    "df_list = []\n",
    "\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        #for all csv files in \\cure, append them to a list\n",
    "        full_path = os.path.join(input_directory, filename)\n",
    "        df = pd.read_csv(full_path, index_col=None, header=0)\n",
    "        df_list.append(df)\n",
    "\n",
    "        # Concatenate all data into one DataFrame\n",
    "        combined_csv = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "combined_csv.to_csv(\"combined_data.csv\", index=False)\n",
    "print('I combined all the \\cure data into one file :))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finiiiished :)\n"
     ]
    }
   ],
   "source": [
    "#Read combined CSV file\n",
    "filename = 'combined_data.csv'\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "#Sort data by 'smiles' and 'weight' in descending order (higher weight is better)\n",
    "sorted_data = data.sort_values(by=['smiles', 'weight'], ascending=[True,False])\n",
    "\n",
    "#Remove duplicates , keeping the first entry after sorting, which is the one with higher weight\n",
    "best_values_data = sorted_data.drop_duplicates(subset='smiles', keep='first')\n",
    "\n",
    "#Sort the cleaned data to the output directory with the same filename\n",
    "best_values_data.to_csv(\"combined_cleaned_data.csv\", index=False)\n",
    "\n",
    "print('Finiiiished :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cured data (before cleaning):\n",
      "Rows Counted 127949 in the csv combined_data.csv:\n",
      "Cleaned data (after cleaning):\n",
      "Rows Counted 115039 in the csv combined_cleaned_data.csv:\n",
      "12910\n"
     ]
    }
   ],
   "source": [
    "print('Cured data (before cleaning):')\n",
    "\n",
    "filename = 'combined_data.csv'\n",
    "\n",
    "with open(filename, 'r', encoding=\"latin-1\") as fileObj:\n",
    "    lines = fileObj.readlines()  # Read once and use multiple times\n",
    "    a = len(lines) - 1  # -1 to exclude the header\n",
    "    print(\"Rows Counted {} in the csv {}:\".format(a, filename))\n",
    "\n",
    "print('Cleaned data (after cleaning):')\n",
    "\n",
    "filename = 'combined_cleaned_data.csv'\n",
    "\n",
    "with open(filename, 'r', encoding=\"latin-1\") as fileObj:\n",
    "    lines = fileObj.readlines()  # Read once and use multiple times\n",
    "    b = len(lines) - 1  # -1 to exclude the header\n",
    "    print(\"Rows Counted {} in the csv {}:\".format(b, filename))\n",
    "\n",
    "print(a - b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
